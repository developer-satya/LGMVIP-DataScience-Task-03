{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab0b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e257fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('songdata.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165df3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57650, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb6004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=5000).drop('link', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52eee439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6bb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower().replace(r'[^\\w\\s]','').replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4b8361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i am stopping by to tell you   i'll be leaving here for good,   to go back to where i came from,   like you always said i should.   i would be a liar if i said that i was fine,   'cause you opened up my head   and you lost some of my mind.      i've been a fool.   i've been full of you.   i've been lying here so long i don't know who i'm lying to.   but i'm set on fire   in spite of you.   i will burn another bridge and hope the river burns up too.   when i'm gone,   you'll be gone too.      our hands are stained the color of the sky above our heads,   with things we haven't done   and words we haven't said.   still the pain will come as some surprise.   when you burn a bridge the smoke gets in your eyes.      no, i've been a fool.   i've been full of you.   i've been lying here so long i don't know who i'm lying to.   but i'm set on fire   in spite of you.   i will burn another bridge and hope the river burns up too.   when i'm gone,   you'll be gone too.      the ashes blow away,   trailing sheets of rain   all along the interstate   somewhere into space.   i've got no place for ashes,   i've got no place for ashes,   i've got no place for ashes anyway.      i've been full of you.   i've been lying here so long i don't know who i'm lying to.   but i'm set on fire   in spite of you.   i will burn another bridge and hope the river burns up too.   when i'm gone,   when i'm gone,   when i'm gone,   you'll be gone too.  \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3260a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenization(txt):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    stemming = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cbe4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36974948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203ad57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvector = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "matrix = tfidvector.fit_transform(df['text'])\n",
    "similarity = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06efd00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.17020727, 0.14450938, ..., 0.05107118, 0.034936  ,\n",
       "       0.00731841])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aef863c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bridge Burning'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['song'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d080eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['song']==''].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033cceef",
   "metadata": {},
   "source": [
    "# recommedation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9795f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(song_df):\n",
    "    idx = df[df['song'] == song_df].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[idx])),reverse=True,key=lambda x:x[1])\n",
    "    \n",
    "    songs = []\n",
    "    for m_id in distances[1:21]:\n",
    "        songs.append(df.iloc[m_id[0]].song)\n",
    "        \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "842ff231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Learn To Say Goodbye',\n",
       " 'Girl Goodbye',\n",
       " 'Goodbye Stranger',\n",
       " \"I'll Never Say Goodbye\",\n",
       " 'Ggodbye Angel',\n",
       " 'Sitting In The Window Of My Room',\n",
       " \"I'll Be Back Someday\",\n",
       " 'High School Musical',\n",
       " 'Gone Crazy',\n",
       " 'Everybody Knows That You Are Insane',\n",
       " \"That's My Impression\",\n",
       " 'Lately',\n",
       " \"Everybody's Crazy\",\n",
       " 'Looking For You',\n",
       " 'Miss The Lights',\n",
       " 'Miss Me Blind',\n",
       " 'Learning How To Smile',\n",
       " 'A Goodbye Joke',\n",
       " 'Kiss And Say Goodbye',\n",
       " 'Good Night']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation('Alma Mater')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b3388",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aba04293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(similarity,open('similarity.pkl','wb'))\n",
    "pickle.dump(df,open('df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "713dc163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sanaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e029a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
